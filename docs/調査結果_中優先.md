承知いたしました。SLASH論文の実装における中優先度の調査項目について、AIリサーチアシスタントとして詳細な技術調査を実施し、実装に直結する形で回答します。

---

## 調査報告：SLASH実装に関する中優先度項目

ご指定いただいた中優先度の4項目について、論文および参考文献に基づき詳細な調査を行いました。以下に各項目の調査結果を報告します。

### 1. Subharmonic Summation (SHS) アルゴリズム詳細

#### 調査結果 (調査日: 2024-08-05)

**結論**
Pitch Guide生成に使用されるSHSは、対数周波数領域において、入力スペクトログラムを整数倍に圧縮（高周波数側へシフト）し、重み付け加算するアルゴリズムです。参考文献 (Ikemiya et al. 2016)と一般的な実装に基づき、サブハーモニック次数はナイキスト周波数によって動的に決定し、重みは論文記載の減衰係数 `0.86^(n-1)` を使用するのが妥当です。

**実装方針**
SHSは以下の手順で実装します。入力は `exp(ψ(S))`、すなわち fine structure spectrum の線形振幅スペクトログラム（形状: `[T, K]`）です。

1.  **対数周波数への変換**:
    *   入力スペクトログラム `[T, K]` を、Pitch Guide `G` と同じ対数周波数スケール（20Hz-2kHz, 1024bins）のスペクトログラム `S_log`（形状: `[T, F]`）に変換します。変換には線形補間を使用します。
    *   この対数スケールの分解能 `p` (cents/bin) を計算しておきます。
        `p = 1200 * log2(2000 / 20) / 1023`

2.  **SHS計算**:
    *   SHSスペクトログラム `S_shs`（形状: `[T, F]`）を `S_log` で初期化します（n=1の項）。
    *   サブハーモニック次数 `n = 2` から `N_max` までループします。`N_max` は、最低F0（例: 20Hz）の `n` 倍音がナイキスト周波数（12kHz）を超えない最大の `n`（例: `floor(12000 / 20) = 600`）、または実用的な上限（例: 10-20）を設定します。
    *   各 `n` において、周波数シフト量（bin単位）を計算します。
        `shift_bins = round(1200 * log2(n) / p)`
    *   `S_log` を `shift_bins` だけ高周波数側（インデックスが大きい方向）にシフトした `S_shifted` を生成します。`torch.roll` を使用するか、スライスで実装します。シフトにより空いた低周波数側はゼロで埋めます。
    *   重み `β_n = 0.86^(n-1)` を計算し、`S_shifted` に乗算します。
    *   `S_shs` に結果を加算します。

```python
# PyTorch風 疑似コード
def subharmonic_summation(s_log, n_max, cents_per_bin):
    s_shs = s_log.clone()  # n=1 の項
    
    for n in range(2, n_max + 1):
        # 対数周波数領域でのシフト量を計算
        shift_bins = round(1200 * torch.log2(torch.tensor(n)) / cents_per_bin)
        
        # スペクトログラムをシフト
        s_shifted = torch.zeros_like(s_log)
        if shift_bins < s_log.shape[-1]:
            s_shifted[..., shift_bins:] = s_log[..., :-shift_bins]
        
        # 重み付けして加算
        weight = 0.86**(n - 1)
        s_shs += weight * s_shifted
        
    return s_shs

# G' の計算
# S_fine_linear = torch.exp(psi_S)
# S_log = convert_to_log_freq_scale(S_fine_linear)
# G_prime = subharmonic_summation(S_log, n_max=10, cents_per_bin=p)
```

**参考資料**
*   Ikemiya et al. 2016: "Singing voice separation and vocal F0 estimation..." - SHSの基本式と重み `β_n = 0.86^(n-1)` を提示。
*   一般的な音声処理ライブラリにおけるSHS実装。

**残課題**
*   最適な `N_max` はデータに依存する可能性があり、実験的な調整が必要です。まず `N_max=10` 程度で実装を開始するのが良いでしょう。

---

### 2. 三角波振動子の実装式

#### 調査結果 (調査日: 2024-08-05)

**結論**
論文の式は、位相 `Φ` が `[0, 1)` の範囲で周期的に変動することを前提とした標準的な三角波の定義です。`Φ` が時間積分で得られるため、`fmod(Φ, 1.0)` または `Φ - torch.floor(Φ)` によって周期内に正規化する必要があります。これにより、微分可能で連続的な三角波が生成されます。

**実装方針**
三角波 `X_t,k` は、正規化された位相 `Φ_norm` を用いて以下のように実装します。

1.  **位相の計算**: 論文通り `Φ_t,k = (fs / (2 * pt * K)) * k` を計算します。
2.  **位相の正規化**: 位相を `[0, 1)` の範囲に正規化します。
    `Φ_norm = Φ_t,k - torch.floor(Φ_t,k)`
3.  **三角波の生成**: 正規化された位相を用いて三角波を生成します。論文の式は `2 * abs(2 * (Φ_norm - 0.5)) - 1` を変形したもので、`4 * abs(Φ_norm - 0.5) - 1` と等価です。

```python
# PyTorch風 疑似コード
def triangle_wave_from_phase(phase):
    """
    Args:
        phase (Tensor): 任意の実数値の位相
    Returns:
        Tensor: [-1, 1] 範囲の三角波
    """
    # 位相を [0, 1) の範囲に正規化
    phase_norm = phase - torch.floor(phase)
    
    # 三角波を計算
    # 4 * abs(phase_norm - 0.5) - 1 は [-1, 1] の三角波を生成する
    # phase_norm=0 -> 1, phase_norm=0.5 -> -1, phase_norm=1 -> 1
    triangle = 4.0 * torch.abs(phase_norm - 0.5) - 1.0
    
    return triangle

# 論文の式は場合分けになっているが、上記一行で実装可能
# if Φ_norm < 0.5:
#    X = 4 * Φ_norm - 1
# else:
#    X = -4 * Φ_norm + 3
# これは 4*abs(Φ_norm-0.5)-1 を変形したものとは少し違う。
# 論文の式を忠実に実装すると、
# X = torch.where(phase_norm < 0.5, -1.0, 4.0 * torch.abs(phase_norm - 0.5) - 1.0)
# これは誤記の可能性が高い。標準的な [-1, 1] 三角波を実装するのが妥当。

# 論文の式を再解釈
# Xt,k = 4 * |Φt,k - ⌊Φt,k⌋ - 0.5| - 1
# これは Φt,k - ⌊Φt,k⌋ が正規化された位相そのものであるため、
# 上記の triangle = 4.0 * torch.abs(phase_norm - 0.5) - 1.0 と完全に一致する。
# したがって、論文の `otherwise` の式が三角波の本体であり、
# `if Φt,k < 0.5` の条件は、位相が非常に小さい場合の特殊処理か、
# あるいは文脈上の誤記の可能性が高い。
# DDSPの文脈では、通常、単純な三角波を用いるため、特殊な条件分岐は不要と判断。
```

**参考資料**
*   DDSP (Differentiable Digital Signal Processing) 関連のオープンソース実装。
*   標準的な波形生成アルゴリズムの解説。

**残課題**
*   論文の `if Φ_t,k < 0.5` の条件分岐の意図が不明確です。これは `Φ` が正規化されていない値であることを前提としている可能性がありますが、式全体との整合性が取れません。まずは標準的な三角波で実装し、問題が生じた場合に再検討するのが現実的です。

---

### 3. データ拡張戦略の最適化

#### 調査結果 (調査日: 2024-08-05)

**結論**
SSL学習の効果を最大化するため、論文で言及されているデータ拡張（ピッチシフト、ノイズ付加、音量変更）を確率的に適用するパイプラインを構築します。各拡張は独立に、かつ一定の確率（例: 50%）で適用するのが一般的です。これにより、モデルは多様な音響条件に対する不変性を学習できます。

**実装方針**
学習時のデータローダー内で、以下の拡張処理を実装します。

1.  **音量変更**:
    *   `±6dB` の範囲でランダムなゲインを適用します。
    *   `gain_db = torch.rand(1) * 12 - 6`
    *   `gain_linear = 10**(gain_db / 20)`
    *   `waveform_aug = waveform * gain_linear`

2.  **ノイズ付加**:
    *   最大SNRが `-6dB` となるようにノイズ（白色ノイズが基本）を加えます。
    *   まず `[-6, 30]` dBなどの広い範囲からランダムなSNR値をサンプリングします。
    *   信号とノイズのパワーを計算し、目標SNRになるようにノイズの振幅をスケーリングして加算します。
    *   `torchaudio.functional.add_noise` が利用できます。

3.  **ピッチシフト**:
    *   これはSLASHの損失関数で直接扱われるため、データセットレベルでの事前拡張は不要です。CQTを計算した後、`C` と `C_shift` を生成する処理がこれに該当します。

4.  **拡張パイプライン**:
    *   学習の各ステップで、原音声 `w` から拡張音声 `w_aug` を生成します。
    *   `w_aug` は音量変更とノイズ付加を確率 `p_aug` (例: 0.7) で適用します。
    *   `w` と `w_aug` それぞれからCQTを計算し (`C`, `C_aug`)、さらに `C` から `C_shift` を生成します。
    *   モデルは `C, C_shift, C_aug` を入力として、対応する損失（`Lcons`, `Lg-shift`, `Laug` など）を計算します。

```python
# PyTorch Dataset __getitem__ 内での処理イメージ
p_aug = 0.7

def augment(waveform):
    if torch.rand(1) < p_aug:
        # 1. Volume change
        gain_db = torch.rand(1) * 12 - 6
        waveform = torchaudio.functional.gain(waveform, gain_db)
        
        # 2. Add noise
        snr_db = torch.rand(1) * 36 - 6 # [-6, 30] dB
        noise = torch.randn_like(waveform)
        waveform = torchaudio.functional.add_noise(waveform, noise, snr_db)
    return waveform

# waveform = load_audio(...)
# waveform_aug = augment(waveform)
# C = cqt(waveform)
# C_aug = cqt(waveform_aug)
# C_shift = create_shifted_cqt(C)
```

**参考資料**
*   PESTO, SPICE 論文: SSLピッチ推定におけるデータ拡張の先行研究。
*   `torchaudio.transforms` のドキュメント: 音声データ拡張の標準的な実装。

**残課題**
*   最適な拡張確率 `p_aug` やSNR範囲は、最終的なモデル性能を見ながら調整が必要です。論文の値は出発点として有効です。

---

### 4. GED損失での S̃₁, S̃₂ 生成方法

#### 調査結果 (調査日: 2024-08-05)

**結論**
Generalized Energy Distance (GED) 損失の反発項 `||ψ(S̃₁) - ψ(S̃₂)||₁` を計算するために必要な2つの異なる生成スペクトログラム `S̃₁` と `S̃₂` は、**同一の入力条件に対して、モデルの確率的な要素を変えて2回フォワードパスを実行する**ことで生成します。SLASHの文脈では、DDSP Synthesizer内の確率的要素（ノイズ励起信号 `e_ap`）がこれに該当します。

**実装方針**
`L_recon` の計算は以下の手順で行います。

1.  **入力の準備**:
    *   Pitch Encoderから予測された `p` (F0), `A` (Aperiodicity), および `H` (Spectral Envelope) を用意します。

2.  **S̃₁ の生成**:
    *   DDSP Synthesizerのフォワードパスを1回実行します。この際、内部で生成されるノイズ励起信号 `e_ap1` はランダムにサンプリングされます。
    *   出力波形 `w̃₁` からスペクトログラム `S̃₁` を計算します。

3.  **S̃₂ の生成**:
    *   **全く同じ `p`, `A`, `H` を用いて**、DDSP Synthesizerのフォワードパスを再度実行します。
    *   この2回目のパスでは、内部のノイズ励起信号 `e_ap2` が **新たにランダムサンプリング** されます。これにより `e_ap1 ≠ e_ap2` となり、結果として `w̃₁ ≠ w̃₂` かつ `S̃₁ ≠ S̃₂` となります。
    *   出力波形 `w̃₂` からスペクトログラム `S̃₂` を計算します。

4.  **損失計算**:
    *   得られた `S̃₁`, `S̃₂` と目標スペクトログラム `S` を用いて、論文のEquation (8) に従って `L_recon` を計算します。

```python
# PyTorch風 疑似コード

# p, A, H はPitch EncoderとSpec Env. Estimatorから取得
predicted_f0 = ...
predicted_aperiodicity = ...
predicted_spec_env = ...

# S̃₁ の生成
# synthesizerは内部で torch.randn を呼び出す
waveform_tilde_1 = synthesizer(predicted_f0, predicted_aperiodicity, predicted_spec_env)
s_tilde_1 = stft(waveform_tilde_1)

# S̃₂ の生成 (同じ入力で再度フォワード)
waveform_tilde_2 = synthesizer(predicted_f0, predicted_aperiodicity, predicted_spec_env)
s_tilde_2 = stft(waveform_tilde_2)

# ターゲットスペクトログラム
s_target = stft(target_waveform)

# GED損失の計算
# fine_structure(S) = log(S) - spectral_envelope(log(S))
l_recon = torch.mean(torch.abs(fine_structure(s_tilde_1) - fine_structure(s_target))) \
        - alpha * torch.mean(torch.abs(fine_structure(s_tilde_1) - fine_structure(s_tilde_2)))

```
**重要**: `S̃₁` と `S̃₂` の生成過程は計算グラフ上で繋がっている必要があります。`S̃₂` の生成時に `p`, `A`, `H` を `detach()` してはいけません。反発項からの勾配が、`S̃₁` と `S̃₂` の両方を生成した `p`, `A`, `H` の予測ネットワークにフィードバックされることで、モデルは単一の点に収束するのではなく、データの多様性を捉えるように学習します。

**参考資料**
*   Gritsenko et al. 2020: "A spectral energy distance for parallel speech synthesis" - GED損失の原典。p.4で「generate two independent samples...using two independently sampled sets of noise variables」と明確に記述されています。

**残課題**
*   `α` (alpha) の値（論文では0.1）は、データセットやモデル構造によって最適な値が異なる可能性があり、チューニング対象となり得ます。