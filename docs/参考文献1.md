ご提示いただいた論文「SLASH: Self-Supervised Speech Pitch Estimation Leveraging DSP-derived Absolute Pitch」の追実装を進めるにあたり、その基盤となっている、あるいは実装に不可欠な先行研究論文をいくつかご紹介します。SLASH は、自己教師あり学習（SSL）の手法と、伝統的なデジタル信号処理（DSP）の手法を巧みに融合させているため、双方の理解が重要になります。

以下に、SLASH の各構成要素を理解し、実装するために特に重要だと考えられる論文を、その理由と共にリストアップしました。

### 1. 中核となる自己教師あり学習（SSL）の枠組みに関する論文

SLASH は、ピッチシフトされたデータを用いて相対的なピッチを学習するという自己教師あり学習のアイデアに基づいています。この中核的なコンセプトを理解するためには、以下の論文が不可欠です。

- **SPICE: Self-supervised pitch estimation** ([https://arxiv.org/abs/1912.07844](https://arxiv.org/abs/1912.07844))
  この論文は、自己教師あり学習によるピッチ推定の代表的な手法である SPICE を提案しています。SLASH が `L_cons` (Pitch consistency loss) として採用している、元の音声とピッチシフトした音声との間でピッチの一貫性を学習させるという基本的な枠組みは、この研究が元になっています。SLASH との違いを明確に理解するためにも、まずこの論文を読むことをお勧めします。

- **NANSY++: Unified voice synthesis with neural analysis and synthesis** ([https://arxiv.org/abs/2211.09407](https://arxiv.org/abs/2211.09407))
  SLASH の論文の 2.2 節で「The architecture of the Pitch Encoder is based on the Pitch encoder of [12]」と明記されている通り、Pitch Encoder の具体的なネットワーク構造はこの NANSY++に基づいています。したがって、Pitch Encoder 部分を正確に実装するためには、この論文のアーキテクチャに関する記述を参照する必要があります。

### 2. 微分可能 DSP（DDSP）と新しい損失関数に関する論文

SLASH の新規性の核心の一つは、微分可能な DSP モジュールを用いて絶対ピッチを直接最適化する点です。この部分の実装には、DDSP のコンセプトと、特殊な損失関数の理解が求められます。

- **DDSP: Differentiable digital signal processing** ([https://arxiv.org/abs/2001.04643](https://arxiv.org/abs/2001.04643))
  この論文は、音声合成器のコンポーネントを微分可能な演算子で構築し、スペクトログラムの損失から逆伝播によってパラメータ（ピッチや振幅など）を最適化する「微分可能デジタル信号処理（DDSP）」の概念を提案しました。SLASH が `L_pseudo` (Pseudo spectrogram loss) を通じて勾配降下で Fo を最適化するアプローチは、この DDSP の思想に基づいています。SLASH では波形を直接生成しない工夫がされていますが、その背景にある考え方を理解するために重要です。

- **A spectral energy distance for parallel speech synthesis** ([https://arxiv.org/abs/2010.15082](https://arxiv.org/abs/2010.15082))
  SLASH の論文の式(8)で使われている `L_recon` の損失関数は、単純な L1 ノルムではなく、Generalized Energy Distance (GED) を採用しています。この GED を提案したのがこの論文です。aperiodicity の学習を安定させるための重要な要素ですので、この損失関数の定義と実装方法を理解するために参照が必要です。

### 3. 基盤となる音声分析合成と信号処理技術に関する論文

SLASH は、音声信号を「基本周波数（Fo）」「スペクトル包絡」「非周期性指標」というパラメータに分解するソース・フィルタモデルに基づいています。また、CQT や SHS といった特定の DSP 技術も利用しています。

- **WORLD: A vocoder-based high-quality speech synthesis system for real-time applications** ([https://www.inf.ie.u-ryukyu.ac.jp/~maekawa/resource/WORLD/WORLD-TIEICE2016.pdf](https://www.inf.ie.u-ryukyu.ac.jp/~maekawa/resource/WORLD/WORLD-TIEICE2016.pdf))
  この論文は、高品質な音声分析合成システムである WORLD ボコーダーを提案しています。SLASH が推定・利用している基本周波数（Fo）、スペクトル包絡（spectral envelope）、非周期性指標（aperiodicity）という３つのパラメータは、まさに WORLD が用いているものと同じです。音声がこれらのパラメータにどのように分解され、また再合成されるのかという基本的な概念を理解する上で非常に参考になります。

- **Singing voice separation and vocal F0 estimation based on mutual combination of robust principal component analysis and subharmonic summation** ([https://ieeexplore.ieee.org/document/7563813](https://ieeexplore.ieee.org/document/7563813))
  SLASH の 2.3 節で導入されている「Pitch guide」は、DSP ベースの手法である Subharmonic Summation (SHS) を用いて計算されます。この SHS の具体的なアルゴリズムを理解するために、引用文献であるこの論文が役立ちます。

- **Calculation of a constant Q spectral transform** ([https://asa.scitation.org/doi/10.1121/1.400408](https://asa.scitation.org/doi/10.1121/1.400408))
  モデルへの入力として、STFT（短時間フーリエ変換）の代わりに CQT（Constant-Q Transform）が使われています。CQT は周波数が高くなるほど時間分解能が高く、低くなるほど周波数分解能が高くなるという特徴があり、音楽や音声の分析でよく用いられます。この変換の理論と計算方法を理解するために、原論文であるこちらを参照すると良いでしょう。

これらの論文を順に読み解いていくことで、SLASH のアーキテクチャの各コンポーネントがどのような背景と思想に基づいて設計されているかを深く理解でき、よりスムーズな追実装につながるかと思います。頑張ってください。
